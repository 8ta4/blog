I'm working on a personal project to improve my spoken language skills. I've created a tool that transcribes everything I say 24/7. My transcript revealed that "uh" and "huh" are my most frequent fillers. It was an "uh-huh" moment!

My goal now is to reduce the filler words I use.

I thought of making another tool to count and analyze filler words.

Does anyone know if there is something like this already, or a better way that experts in speech language pathology would recommend? If it exists, I can use it and save some time.

- **Filler Word Analysis**: The tool should tally up common filler words and provide their frequency.
- **Baseline Comparison**: It should compare my filler word usage with standard linguistic data (like Google's n-gram dataset) to determine if I'm above or below the norm.
- **Sorting**: The tool should rank filler words based on how much their frequency surpasses the baseline.
- **Local Operation**: The tool should operate locally to ensure privacy, as the transcripts are raw and unfiltered.
- **User Interface**:  I like a command line interface that takes a text file as input and can also read from standard input. But hey, a graphical user interface could work too.
