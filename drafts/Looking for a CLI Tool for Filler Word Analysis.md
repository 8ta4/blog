I'm working on a personal project to improve my spoken language skills. I've created a tool that transcribes everything I say 24/7. My transcript revealed that "uh" and "huh" are my most frequent fillers. It was an "uh-huh" moment!

My goal now is to reduce the filler words I use.

I've been toying with the idea of a separate tool. Is there something like this already out there, or perhaps a better method that speech language pathology gurus would vouch for? If it's already in existence, I could just adopt it and save some development time.

- **Filler Word Analysis**: The tool should tally up common filler words and provide their frequency.
- **Baseline Comparison**: It should compare my filler word usage with standard linguistic data (like Google's n-gram dataset) to determine if I'm above or below the norm.
- **Sorting**: The tool should rank filler words based on how much their frequency surpasses the baseline.
- **Local Operation**: The tool should operate locally to ensure privacy, as the transcripts are raw and unfiltered.
- **User Interface**: It should be a CLI that accepts a text file as an input argument and can also handle standard input.
